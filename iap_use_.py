# -*- coding: utf-8 -*-
"""IAP-USE .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FiavV1Awml3jwsDf9ki_zjtIfeankj4i

# **Latest Version of transformers from ðŸ¤— Model Hub**
"""

pip install git+https://github.com/huggingface/transformers.git

"""# **import required Libs**"""

from transformers import ViTFeatureExtractor, ViTForImageClassification
from PIL import Image
import requests

"""# **Download Image from the given URL**"""

# url=https://tiimg.tistatic.com/fp/1/005/297/dry-shyama-basil-tulsi-leaves-leaf-and-stem-894.jpg
url='https://images.immediate.co.uk/production/volatile/sites/10/2018/02/f185aed9-856e-426e-b69a-5427cf843cbe-8547772.jpg'
image = Image.open(requests.get(url, stream=True).raw)

"""# **Display The downloaded image**"""

#from IPython.display import Image
display(image)

"""# **Download Pre-trained Model**"""

# feature_extractor = ViTFeatureExtractor.from_pretrained("Amrrs/south-indian-foods")



# Load model directly
from transformers import AutoFeatureExtractor, AutoModelForImageClassification

feature_extractor= AutoFeatureExtractor.from_pretrained("AnsumanBhujabal/Indian-Ayurvedic-Products")
model = AutoModelForImageClassification.from_pretrained("AnsumanBhujabal/Indian-Ayurvedic-Products")

"""# **Extract Features**"""

inputs = feature_extractor(images=image, return_tensors="pt")

"""# **Model Inference**"""

outputs = model(**inputs)

logits = outputs.logits

"""# **model predicts one of the 1000 ImageNet classes**"""

predicted_class_idx = logits.argmax(-1).item()
print("Predicted class:", model.config.id2label[predicted_class_idx])

