# -*- coding: utf-8 -*-
"""Text Data Pre-Processing-use Case.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1495Q7wg5OfFXUeXvsiH3JtvGxJBrBMhg

# **IMPORT**
"""

import numpy as np
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

data= pd.read_csv('/content/drive/MyDrive/Datasets/fake_news_dataset.csv')

"""# **Download Stopwords**"""

nltk.download('stopwords')

print(stopwords.words('english'))

data.head

data.describe()

#0-- real news
#1-- fake news

data.shape

"""# **Checking For Missing Values**"""

data.isnull().sum()

"""# **Handling The Missing Value With Null String**"""

data=data.fillna('')

"""# **Merge Author and news Title**"""

data['content']= data['author']+' '+data['title']
# data['content'] = data['content'].astype(str)
print(data['content'])

data.head()

"""# **Separating Feature and target,(here content and label)**"""

X=data.drop(columns='label', axis =1)
Y=data['label']

print(X)

"""# **Stemming**"""

port_stem= PorterStemmer()

#Function that converts all words to key words and ignores stopwors
#Using Regex to find words
def stemming(content):
    stemmed_content = re.sub('[^a-zA-Z]',' ',content)
    stemmed_content = stemmed_content.lower()
    stemmed_content = stemmed_content.split()
    stemmed_content = [port_stem.stem(word) for word in stemmed_content
                       if not word in stopwords.words('english')]
    stemmed_content = ' '.join(stemmed_content)
    return stemmed_content

data['content']=data['content'].apply(stemming)

print(data['content'])

"""# **Feature Extraction**"""

X= data['content'].values
Y=data['label'].values

print(X)

print(Y.shape)

"""# **Text To  Feature Vectors**"""

vector=TfidfVectorizer()
vector.fit(X)
X=vector.transform(X)

print(X)

